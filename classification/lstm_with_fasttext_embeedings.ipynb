{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cybertech2/tomekg/NLP_learning/.venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from torch import load as torch_load\n",
    "from torch.optim import Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from lstm_utils.model import BiLSTM, LSTM\n",
    "from lstm_utils.train import train, test\n",
    "from lstm_utils.utils import vectorize_text\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cybertech2/tomekg/NLP_learning/.venv/lib/python3.8/site-packages/datasets/load.py:1461: FutureWarning: The repository for emotion contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/emotion\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 16000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = load_dataset('emotion')\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.set_format('pandas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = vectorize_text(X=ds['train']['text'], y=ds['train']['label'], max_num_of_words=20)\n",
    "val_ds = vectorize_text(X=ds['validation']['text'], y=ds['validation']['label'], max_num_of_words=20)\n",
    "test_ds = vectorize_text(X=ds['test']['text'], y=ds['test']['label'], max_num_of_words=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dl = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_dl = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_DIM = 128\n",
    "NUM_LAYERS_LSTM = 2\n",
    "DROPOUT_LSTM = 0.2\n",
    "DROPOUT_CLF = 0.2\n",
    "LEARNING_RATE = 0.01\n",
    "NUM_EPOCHS = 100\n",
    "PATIENCE = 20\n",
    "\n",
    "lstm = LSTM(\n",
    "    embedding_dim=20,\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    output_dim=6,\n",
    "    num_layers_lstm=NUM_LAYERS_LSTM,\n",
    "    dropout_lstm=DROPOUT_LSTM,\n",
    "    dropout_clf=DROPOUT_CLF\n",
    ")\n",
    "optimizer = Adam(lstm.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "train(\n",
    "    model=lstm,\n",
    "    optimizer=optimizer,\n",
    "    loss_fn=CrossEntropyLoss(),\n",
    "    epochs=NUM_EPOCHS,\n",
    "    train_dl=train_dl,\n",
    "    val_dl=val_dl,\n",
    "    patience=PATIENCE,\n",
    "    print_metrics=True,\n",
    "    device='cuda',\n",
    "    best_model_path='lstm_utils/best_lstm.pth'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm.load_state_dict(torch_load.load('lstm_utils/best_lstm.pth'))\n",
    "lstm.eval()\n",
    "test(\n",
    "    model=lstm,\n",
    "    dataloader=test_dl,\n",
    "    device='cuda'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_DIM = 128\n",
    "NUM_LAYERS_LSTM = 2\n",
    "DROPOUT_LSTM = 0.2\n",
    "DROPOUT_CLF = 0.2\n",
    "LEARNING_RATE = 0.01\n",
    "NUM_EPOCHS = 100\n",
    "PATIENCE = 20\n",
    "\n",
    "bilstm = BiLSTM(\n",
    "    embedding_dim=20,\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    output_dim=6,\n",
    "    num_layers_lstm=NUM_LAYERS_LSTM,\n",
    "    dropout_lstm=DROPOUT_LSTM,\n",
    "    dropout_clf=DROPOUT_CLF\n",
    ")\n",
    "optimizer = Adam(bilstm.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "train(\n",
    "    model=bilstm,\n",
    "    optimizer=optimizer,\n",
    "    loss_fn=CrossEntropyLoss(),\n",
    "    epochs=NUM_EPOCHS,\n",
    "    train_dl=train_dl,\n",
    "    val_dl=val_dl,\n",
    "    patience=PATIENCE,\n",
    "    print_metrics=True,\n",
    "    device='cuda',\n",
    "    best_model_path='lstm_utils/best_bilstm.pth'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bilstm.load_state_dict(torch_load.load('lstm_utils/best_bilstm.pth'))\n",
    "bilstm.eval()\n",
    "test(\n",
    "    model=bilstm,\n",
    "    dataloader=test_dl,\n",
    "    device='cuda'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
