## NLP projects
The repository contains simple projects - basic NLP tasks, from my NLP classes from university and from self-study.

### Classification
The repository contains a comparison of models: 
- Logistic Regression and SVM ("classic" algorithms, trained on [DistilBERT](https://huggingface.co/docs/transformers/en/model_doc/distilbert) embeedings),
- LSTM and BiLSTM (custom models, written with Pytorch, trained on Fasttext embeedings), 
- finetuned DistilBERT

trained in the task of emotions classification on [emotion dataset](https://huggingface.co/datasets/dair-ai/emotion).


### Adapters
The repository contains a comparison of DistilBERT models trained in the task of emotions classification (emotion dataset). Compared models are:
- DistilBERT with freezed first 6, 4 and 2 layers,
- DistilBERT trained with bottleneck [adapters](https://github.com/adapter-hub/adapters),
- unfreezed DistilBERT.


### Named entity recognition
The repository contains a dataset preprocessing and [XLM-RoBERTa](https://huggingface.co/docs/transformers/model_doc/xlm-roberta) model finetuning in the named entity recognition task on the subset ('de', 'fr', 'it, 'en') of [xtreme dataset](https://huggingface.co/datasets/google/xtreme). Moreover cross-ligual transfer has been examined.  

### Text to Text generation


### Generation
The repository contains a short study of the influence of parameters (temperature, number of beams, topk, topp) on the quality of the output generated by the trained [gpt2](https://huggingface.co/openai-community/gpt2) model.


### Self attention from scrach
